{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries (including tenacity for retries)\n",
        "!pip install google-generativeai faiss-cpu pandas matplotlib tenacity \"chromadb==0.6.3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kkHNSlDFCpFW",
        "outputId": "be3b94d1-711a-435d-8a4c-e664d1e05fff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (9.1.2)\n",
            "Requirement already satisfied: chromadb==0.6.3 in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (2.11.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (0.115.12)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (0.34.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (2.0.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (3.24.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (4.13.1)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (1.21.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (1.32.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (1.32.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (0.53b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (1.32.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (32.0.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3) (13.9.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.164.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==0.6.3) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb==0.6.3) (0.46.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.69.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.6.3) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.6.3) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.6.3) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.6.3) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.6.3) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (1.17.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.6.3) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.6.3) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb==0.6.3) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.6.3) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.6.3) (8.6.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3) (1.32.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3) (1.32.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.53b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.53b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.53b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (0.53b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.6.3) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.6.3) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb==0.6.3) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.6.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.6.3) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb==0.6.3) (0.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.6.3) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.6.3) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb==0.6.3) (0.30.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.6.3) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.6.3) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (1.1.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.6.3) (15.0.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.6.3) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.6.3) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.6.3) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.6.3) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb==0.6.3) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.6.3) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.6.3) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "k6EASnkkA56B"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import time\n",
        "import google.generativeai as genai\n",
        "from google import genai as genai2\n",
        "from google.genai import types\n",
        "import pandas as pd\n",
        "import faiss\n",
        "import numpy as np\n",
        "from tenacity import retry, wait_exponential\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import logging\n",
        "from IPython.display import Markdown\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load API key from Kaggle Secrets\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=api_key)\n"
      ],
      "metadata": {
        "id": "i-bOS-YCC9o6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List models with default page size (50) [[2]]\n",
        "models = genai.list_models()\n",
        "\n",
        "# Print model names\n",
        "for model in models:\n",
        "    print(f\"Model name: {model.name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 858
        },
        "collapsed": true,
        "id": "PA8iG0QjDXY4",
        "outputId": "733ab57f-d038-4908-9bdf-b8232fe9e7f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model name: models/chat-bison-001\n",
            "Model name: models/text-bison-001\n",
            "Model name: models/embedding-gecko-001\n",
            "Model name: models/gemini-1.0-pro-vision-latest\n",
            "Model name: models/gemini-pro-vision\n",
            "Model name: models/gemini-1.5-pro-latest\n",
            "Model name: models/gemini-1.5-pro-001\n",
            "Model name: models/gemini-1.5-pro-002\n",
            "Model name: models/gemini-1.5-pro\n",
            "Model name: models/gemini-1.5-flash-latest\n",
            "Model name: models/gemini-1.5-flash-001\n",
            "Model name: models/gemini-1.5-flash-001-tuning\n",
            "Model name: models/gemini-1.5-flash\n",
            "Model name: models/gemini-1.5-flash-002\n",
            "Model name: models/gemini-1.5-flash-8b\n",
            "Model name: models/gemini-1.5-flash-8b-001\n",
            "Model name: models/gemini-1.5-flash-8b-latest\n",
            "Model name: models/gemini-1.5-flash-8b-exp-0827\n",
            "Model name: models/gemini-1.5-flash-8b-exp-0924\n",
            "Model name: models/gemini-2.5-pro-exp-03-25\n",
            "Model name: models/gemini-2.5-pro-preview-03-25\n",
            "Model name: models/gemini-2.0-flash-exp\n",
            "Model name: models/gemini-2.0-flash\n",
            "Model name: models/gemini-2.0-flash-001\n",
            "Model name: models/gemini-2.0-flash-exp-image-generation\n",
            "Model name: models/gemini-2.0-flash-lite-001\n",
            "Model name: models/gemini-2.0-flash-lite\n",
            "Model name: models/gemini-2.0-flash-lite-preview-02-05\n",
            "Model name: models/gemini-2.0-flash-lite-preview\n",
            "Model name: models/gemini-2.0-pro-exp\n",
            "Model name: models/gemini-2.0-pro-exp-02-05\n",
            "Model name: models/gemini-exp-1206\n",
            "Model name: models/gemini-2.0-flash-thinking-exp-01-21\n",
            "Model name: models/gemini-2.0-flash-thinking-exp\n",
            "Model name: models/gemini-2.0-flash-thinking-exp-1219\n",
            "Model name: models/learnlm-1.5-pro-experimental\n",
            "Model name: models/gemma-3-1b-it\n",
            "Model name: models/gemma-3-4b-it\n",
            "Model name: models/gemma-3-12b-it\n",
            "Model name: models/gemma-3-27b-it\n",
            "Model name: models/embedding-001\n",
            "Model name: models/text-embedding-004\n",
            "Model name: models/gemini-embedding-exp-03-07\n",
            "Model name: models/gemini-embedding-exp\n",
            "Model name: models/aqa\n",
            "Model name: models/imagen-3.0-generate-002\n",
            "Model name: models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize recommended models [[1]][[3]]\n",
        "core_model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp')       # For reasoning/RAG\n",
        "embedding_model = genai.GenerativeModel('text-embedding-004')     # For vector search\n",
        "vision_model = genai.GenerativeModel('gemini-2.0-flash')         # For images\n",
        "flash_model = genai.GenerativeModel('gemini-1.5-flash-8b')        # Lightweight tasks\n",
        "lcw_model = genai.GenerativeModel('gemini-1.5-pro-latest') #Long context window model (2M tokens)\n",
        "audio_model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "client = genai2.Client(api_key=api_key)\n",
        "\n",
        "# Load real dataset (replace with your own)\n",
        "# Example: Crime case data from https://www.kaggle.com/datasets\n",
        "#df = pd.read_csv(\"/kaggle/input/crime-data/cases.csv\")  # Replace with your dataset"
      ],
      "metadata": {
        "id": "K2GfnasFCIKc"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process a large case file (e.g., 10,000+ tokens, long context window)\n",
        "with open(\"/content/drive/MyDrive/Gen AI Project/case.txt\", \"r\") as f:\n",
        "    long_case = f.read()\n",
        "\n",
        "response = core_model.generate_content(f\"Summarize key suspects: {long_case}\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "ek4UE33OCVEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "collapsed": true,
        "outputId": "1b6188ae-cb9d-4762-fd9a-c458c33836d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The key suspects in this case are:\n",
            "\n",
            "1.  **Asif Sayeed:** He is the individual who wholly owns **Management Principles, Inc. (MPI)** and is the central figure in devising the scheme to bypass the Healthcare Consortium of Illinois' referral process.\n",
            "\n",
            "2.  **Management Principles, Inc. (MPI):** This is Sayeed's healthcare management company. MPI signed the Management Services Agreement with the Healthcare Consortium, through which they gained access to patient data. MPI then used this data to solicit patients and forward them to Vital and Physician Care. MPI made payments to the Consortium under the guise of \"management services\" which were actually kickbacks for patient referrals (in the form of data access).\n",
            "\n",
            "3.  **Vital Home & Healthcare:** This is one of the smaller healthcare companies managed by MPI. Vital provided home-based medical services to Medicare recipients, billed Medicare for services to patients obtained through the scheme, and split the fees with MPI.\n",
            "\n",
            "4.  **Physician Care Services:** Similar to Vital, this is another healthcare company managed by MPI. Physician Care also provided home-based medical services, billed Medicare for patients gained via the scheme, and shared the revenue with MPI.\n",
            "\n",
            "These four entities (Sayeed and his three companies) are the defendants-appellants who were found liable for violating the Anti-Kickback Statute and the False Claims Act due to their scheme involving the Healthcare Consortium and Medicare billing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_examples = \"\"\"\n",
        "Example 1:\n",
        "Clues: [\"Alibi: Home at 8 PM\", \"Car seen leaving at 7:45 PM\"]\n",
        "Anomaly: \"Alibi conflict: Car movement contradicts stated location.\"\n",
        "\n",
        "Example 2:\n",
        "Clues: [\"No forced entry\", \"Phone destroyed\"]\n",
        "Anomaly: \"Phone destruction suggests evidence tampering.\"\n",
        "\n",
        "Example 3:\n",
        "Clues: [\"Victim’s phone pinged Tower A at 8 PM\", \"Suspect’s phone pinged Tower B at 8:05 PM\"]\n",
        "Anomaly: \"Geolocation mismatch suggests suspect was elsewhere.\"\n",
        "\"\"\"\n",
        "\n",
        "@retry(wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def detect_anomalies(clues):\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        {few_shot_examples}\n",
        "\n",
        "        New Clues:\n",
        "        {clues}\n",
        "\n",
        "        Identify anomalies:\n",
        "        \"\"\"\n",
        "        return core_model.generate_content(prompt).text\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Anomaly detection failed: {e}\")\n",
        "        return \"Error analyzing anomalies\""
      ],
      "metadata": {
        "id": "EAsg9ujvCTaV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    (\n",
        "        [\"Suspect reported $20k annual income\", \"Purchased luxury car worth $80k in cash\"],\n",
        "        \"Financial anomaly\"\n",
        "    ),\n",
        "    (\n",
        "        [\"Suspect attended meeting in New York at 3 PM\", \"Witness saw suspect in Los Angeles at 3:30 PM\"],\n",
        "        \"Geospatial impossibility\"\n",
        "    ),\n",
        "    (\n",
        "        [\"Crime scene report: No weapons found\", \"Bloody knife discovered in suspect's trunk\"],\n",
        "        \"Evidence contradiction\"\n",
        "    ),\n",
        "    (\n",
        "        [\"Suspect claims to fear heights\", \"Security footage shows suspect on rooftop at 2 AM\"],\n",
        "        \"Behavioral anomaly\"\n",
        "    )\n",
        "]\n",
        "\n",
        "for clues, case_type in test_cases:\n",
        "    print(f\"\\nTesting {case_type}:\")\n",
        "    print(detect_anomalies(clues))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "66oHQuYzFE_a",
        "outputId": "625b0d0a-ab55-4877-e65d-fd6af069446b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Financial anomaly:\n",
            "Anomaly: \"Financial anomaly: Cash purchase of luxury car inconsistent with reported income.\"\n",
            "\n",
            "Testing Geospatial impossibility:\n",
            "Anomaly: \"Geographic impossibility: Suspect cannot be in New York and Los Angeles within 30 minutes.\"\n",
            "\n",
            "Testing Evidence contradiction:\n",
            "Anomaly: \"Weapon anomaly: Knife in suspect's trunk contrasts 'no weapon at scene'.\"\n",
            "\n",
            "Testing Behavioral anomaly:\n",
            "Anomaly: \"Height fear contradiction: Rooftop presence contradicts claimed fear of heights.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 5: Analyze image (supports URLs or local files)\n",
        "def analyze_image(image_source):\n",
        "    try:\n",
        "        # Case 1: Public URL (e.g., \"https://example.com/image.jpg\")\n",
        "        if image_source.startswith((\"http://\", \"https://\")):\n",
        "            response = vision_model.generate_content(\n",
        "                [image_source, \"Describe this image for a criminal investigation.\"]\n",
        "            )\n",
        "        # Case 2: Local file path (e.g., \"/kaggle/input/crime_scene.jpg\")\n",
        "        else:\n",
        "            response = vision_model.generate_content(\n",
        "                [image_source, \"Describe this image for a criminal investigation.\"]\n",
        "            )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "rNRCus7NFyIs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with a public URL\n",
        "#image_url = \"https://example.com/crime_scene.jpg\"\n",
        "#print(analyze_image(image_url))\n",
        "\n",
        "# Test with a local file (ensure the file exists in your Kaggle environment)\n",
        "image_path = \"/content/drive/MyDrive/Gen AI Project/gettyimages-588357220-170667a.jpg\"\n",
        "print(analyze_image(image_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "id": "AG5vH-T5Ivkd",
        "outputId": "2ae4487c-41db-487f-e419-d098898819db",
        "collapsed": true
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, I will analyze the image to provide a detailed description for a criminal investigation, focusing on potentially relevant details. Please keep in mind I am an AI, and this is just an interpretation. A real investigation would require human expertise.\n",
            "\n",
            "**General Description:**\n",
            "\n",
            "The image appears to depict an interior scene, possibly a residence. It shows a room that is in a state of significant disarray. The lighting is somewhat dim, possibly from natural light filtering through a window, but this is not clear. The overall impression is one of neglect and potential chaos.\n",
            "\n",
            "**Specific Details:**\n",
            "\n",
            "*   **Dominant Feature: Mess and Disarray:** The most striking aspect is the extreme untidiness. Objects are scattered throughout the room. There is clutter on the floor, on furniture, and potentially on other surfaces not fully visible.\n",
            "*   **Furniture/Objects:**\n",
            "    *   There appears to be a bed or a couch (partially visible). The bedding or cushions may be dishevelled.\n",
            "    *   There are assorted objects scattered around: clothing, papers, containers, and other unidentified items.\n",
            "*   **Condition of the Room:** The room shows signs of neglect.\n",
            "*   **Potential Points of Interest for Investigation:**\n",
            "    *   **Evidence of Disturbance:** Consider whether the mess is simply untidiness or if it suggests a struggle or forced entry. Look for signs of broken objects, overturned furniture, or items that seem deliberately thrown or damaged.\n",
            "    *   **Items of Significance:** Focus on any items that seem out of place or unusual for the context. This could include:\n",
            "        *   Weapons or potential weapons.\n",
            "        *   Drugs or drug paraphernalia.\n",
            "        *   Valuable items that are damaged or discarded.\n",
            "        *   Documents or papers with relevant information (names, addresses, dates, etc.).\n",
            "        *   Containers or packages that seem suspicious.\n",
            "    *   **Blood or Bodily Fluids:** Carefully examine all surfaces for any stains that could be blood or other bodily fluids. Pay close attention to carpets, upholstery, and areas where a struggle might have occurred.\n",
            "    *   **Points of Entry:** Assess the condition of doors and windows. Are there signs of forced entry or damage?\n",
            "    *   **Personal Items:** Look for items that might help identify the occupant(s) of the room:\n",
            "        *   Photographs.\n",
            "        *   Letters or correspondence.\n",
            "        *   Identification documents.\n",
            "        *   Medications.\n",
            "\n",
            "**Recommendations for Investigators:**\n",
            "\n",
            "*   **Secure the Scene:** Prevent any further contamination or disturbance of the scene.\n",
            "*   **Document Everything:** Take detailed photographs and videos of the entire scene, including close-ups of any potential evidence.\n",
            "*   **Systematic Search:** Conduct a thorough and systematic search of the room, working from the least disturbed areas to the most disturbed areas.\n",
            "*   **Evidence Collection:** Carefully collect and preserve any potential evidence, following proper chain-of-custody procedures.\n",
            "*   **Forensic Analysis:** Submit any collected evidence for appropriate forensic analysis (e.g., DNA testing, fingerprinting, drug analysis).\n",
            "*   **Interviews:** Interview potential witnesses, neighbors, and anyone who may have information about the occupant(s) of the room or any recent events that may have occurred there.\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "*   **Perspective:** My analysis is based solely on the image provided. The perspective and angle of the photograph may limit the visibility of certain details.\n",
            "*   **Context:** The interpretation of the scene depends heavily on the context of the investigation.\n",
            "*   **Expertise:** This description is not a substitute for the expertise of trained investigators and forensic professionals.\n",
            "\n",
            "**Disclaimer:** This analysis is for informational purposes only and should not be considered legal advice or a substitute for professional investigative services.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload audio file to Gemini for processing (supports MP3/WAV/FLAC ≤25MB)\n",
        "audio_file = genai.upload_file(path=\"/content/drive/MyDrive/Gen AI Project/criminal_test.mp3\")\n",
        "\n",
        "# Define analysis prompt to guide Gemini's evaluation of the testimony\n",
        "prompt = \"What do you think of this suspect's testimony\"\n",
        "\n",
        "# Define analysis prompt to guide Gemini's evaluation of the testimony\n",
        "response = audio_model.generate_content([prompt, audio_file])\n",
        "\n",
        "# Print Gemini's analysis results\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "collapsed": true,
        "id": "0hXwYa6rNgfj",
        "outputId": "cc73bfd9-5b8a-414d-cf28-3694cf5477d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This testimony raises several red flags suggesting potential guilt or, at the very least, that the suspect is withholding information:\n",
            "\n",
            "* **Overly defensive and repetitive:** The suspect repeatedly insists they did nothing wrong, even before being directly accused.  Phrases like \"I swear, officer\" and \"I didn't do anything wrong\" are used multiple times, which can be a sign of nervousness and an attempt to overcompensate.\n",
            "* **Unsolicited information and changing story:** The suspect offers details without being prompted, such as walking past the gas station and not going inside.  Later, they change their story, saying they might have seen someone running out but couldn't get a good look.  The evolving narrative suggests they are trying to manage the information they reveal.\n",
            "* **Specific denials:**  Focusing on specifics like \"I didn't touch the cash register\" or \"I've never even stolen a candy bar\" feels overly precise and can indicate an attempt to deflect attention from other potential actions.\n",
            "* **Contradictions:** The suspect denies being in the security footage but then immediately provides an alibi for the clothing the person in the footage is wearing (a black jacket), even claiming they don't own one. This rapid shift and contradictory statement is highly suspicious.\n",
            "* **Bringing up a roommate:** Mentioning the roommate and then immediately retracting it suggests the roommate might have some involvement, and the suspect is trying to conceal it.\n",
            "* **Shifting blame and seeking sympathy:** The suspect asks for water, claims their throat is dry, says they just want to help, and worries about their mother's reaction. These are attempts to deflect attention and gain sympathy.\n",
            "* **Sudden demand for a lawyer (followed by backtracking):** The abrupt shift to demanding a lawyer, then backtracking by saying they don't need one because they're innocent, indicates growing fear of legal consequences and an awareness that their story is unraveling.\n",
            "\n",
            "\n",
            "In short, the suspect's nervousness, contradictory statements, changing story, and unsolicited details create a strong impression of deception. While not definitive proof of guilt, this testimony would likely be viewed with considerable suspicion by law enforcement.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask questions about cases with RAG system\n",
        "CASE1=\"On April 10, 2025, downtown Metropolis witnessed a daring burglary at a high-end jewelry store late one night. At around 11:30 PM, local police responded to frantic calls about the incident. Surveillance footage revealed a masked individual using specialized tools to disarm the alarm system. Investigators have gathered crucial evidence, such as fingerprints and forensic samples. The case remains active as detectives continue piecing together the events through witness interviews and further footage review.\"\n",
        "CASE2=\"In the industrial district on March 15, 2025, an abandoned warehouse became the scene of an unsettling break-in. Late in the evening, concerned residents reported suspicious activity in the area, which prompted a swift investigation. Security cameras later captured an unidentified person near the warehouse, and early findings indicated that the intruder had tampered with the building's security systems. Authorities recovered digital logs, partial footprints, and burglary tools from the site. The investigation is still ongoing, with forensic experts closely examining the evidence.\"\n",
        "CASE3=\"On February 20, 2025, a serene suburban neighborhood was shocked by a bold bank robbery. Around midday, an armed suspect entered a local bank, swiftly overpowering the security measures in place. Witnesses described the event as both chaotic and frightening as the suspect executed the crime with apparent precision. Banking security cameras captured the entire sequence, showing the suspect's rapid actions and subsequent escape. Detectives have collected vital evidence, including the surveillance footage, detailed witness statements, and a discarded mask. The incident has raised community concern, and the investigation continues with multiple leads under review.\"\n",
        "\n",
        "documents=[CASE1, CASE2, CASE3]"
      ],
      "metadata": {
        "id": "oXT6j_97CM-g"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import config\n",
        "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
        "from google.api_core import retry\n",
        "from google.genai import types\n",
        "\n",
        "# Define a helper to retry when per-minute quota is reached.\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "class GeminiEmbeddingFunction(EmbeddingFunction):\n",
        "    # boolean to specify if the generation is for documents or queries\n",
        "    document_mode=True\n",
        "\n",
        "    @retry.Retry(predicate=is_retriable)\n",
        "    def __call__(self, input: Documents) -> Embeddings:\n",
        "        if self.document_mode:\n",
        "            embedding_task = \"retrieval_document\"\n",
        "        else:\n",
        "            embedding_task = \"retrieval_query\"\n",
        "\n",
        "        response = client.models.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            contents=input,\n",
        "            config=types.EmbedContentConfig(\n",
        "                task_type=embedding_task,\n",
        "            ),\n",
        "        )\n",
        "        return [e.values for e in response.embeddings]"
      ],
      "metadata": {
        "id": "sqISyLdwCdLc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "\n",
        "DB_NAME = \"casesdb\"\n",
        "\n",
        "embed_fn = GeminiEmbeddingFunction()\n",
        "embed_fn.document_mode = True\n",
        "\n",
        "chroma_client = chromadb.Client()\n",
        "db = chroma_client.get_or_create_collection(name=DB_NAME, embedding_function=embed_fn)\n",
        "\n",
        "db.add(documents=documents, ids=[str(i) for i in range(len(documents))])"
      ],
      "metadata": {
        "id": "9bWRrqt58Rnm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Switch to query mode when generating embeddings.\n",
        "embed_fn.document_mode = False\n",
        "\n",
        "# Search the Chroma DB using the specified query.\n",
        "query = \"what specific evidence was gathered during the jewelry store burglary?\"\n",
        "\n",
        "result = db.query(query_texts=[query], n_results=1)\n",
        "[all_passages] = result[\"documents\"]\n",
        "\n",
        "Markdown(all_passages[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "_eAulytk8Z0t",
        "outputId": "ee21b45d-b892-4a01-a38b-15298989c174"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "On April 10, 2025, downtown Metropolis witnessed a daring burglary at a high-end jewelry store late one night. At around 11:30 PM, local police responded to frantic calls about the incident. Surveillance footage revealed a masked individual using specialized tools to disarm the alarm system. Investigators have gathered crucial evidence, such as fingerprints and forensic samples. The case remains active as detectives continue piecing together the events through witness interviews and further footage review."
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_oneline = query.replace(\"\\n\", \" \")\n",
        "\n",
        "# This prompt is where you can specify any guidance on tone, or what topics the model should stick to, or avoid.\n",
        "prompt = f\"\"\"You are a helpful and informative bot that answers questions using text from the reference passage included below.\n",
        "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.\n",
        "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and\n",
        "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
        "\n",
        "QUESTION: {query_oneline}\n",
        "\"\"\"\n",
        "\n",
        "# Add the retrieved documents to the prompt.\n",
        "for passage in all_passages:\n",
        "    passage_oneline = passage.replace(\"\\n\", \" \")\n",
        "    prompt += f\"PASSAGE: {passage_oneline}\\n\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNpYh5On81yD",
        "outputId": "22e4f622-4000-4372-edc7-f417e0870faa"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a helpful and informative bot that answers questions using text from the reference passage included below.\n",
            "Be sure to respond in a complete sentence, being comprehensive, including all relevant background information.\n",
            "However, you are talking to a non-technical audience, so be sure to break down complicated concepts and\n",
            "strike a friendly and converstional tone. If the passage is irrelevant to the answer, you may ignore it.\n",
            "\n",
            "QUESTION: what specific evidence was gathered during the jewelry store burglary?\n",
            "PASSAGE: On April 10, 2025, downtown Metropolis witnessed a daring burglary at a high-end jewelry store late one night. At around 11:30 PM, local police responded to frantic calls about the incident. Surveillance footage revealed a masked individual using specialized tools to disarm the alarm system. Investigators have gathered crucial evidence, such as fingerprints and forensic samples. The case remains active as detectives continue piecing together the events through witness interviews and further footage review.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = core_model.generate_content(\n",
        "    contents=prompt\n",
        "    )\n",
        "\n",
        "Markdown(answer.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "wabeejXZ9iKC",
        "outputId": "49121166-6a61-4b1b-cf3f-d9f0772b38a6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "During the jewelry store burglary, investigators gathered specific evidence like fingerprints and forensic samples to help them solve the case."
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tenacity import retry, wait_exponential\n",
        "\n",
        "@retry(wait=wait_exponential(multiplier=1, min=4, max=10))\n",
        "def quick_summary(file_path):\n",
        "    try:\n",
        "        # Read text from the file\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "            text = file.read()\n",
        "\n",
        "        # Generate summary with Gemini Flash (fast model)\n",
        "        response = flash_model.generate_content(\n",
        "            f\"Summarize this in 1 sentence: {text}\"\n",
        "        )\n",
        "        return response.text\n",
        "    except FileNotFoundError:\n",
        "        return \"Error: The file was not found. Check the path.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Example usage\n",
        "print(quick_summary(\"/content/drive/MyDrive/Gen AI Project/case.txt\"))  # Replace with your file path"
      ],
      "metadata": {
        "id": "hUAhslZFFft-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ebf597b2-9d00-4709-f335-3d2debd84cf9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Seventh Circuit Court of Appeals affirmed a $6 million judgment against healthcare companies for violating the Anti-Kickback Statute and False Claims Act, but remanded the case for the district court to determine which Medicare claims were directly attributable to the defendants' illegal kickback scheme.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample case data (text clues)\n",
        "data = {\n",
        "    \"clue_id\": [1, 2, 3, 4],\n",
        "    \"text\": [\n",
        "        \"Victim last seen near park at 8 PM [[1]]\",\n",
        "        \"Witness heard argument in alleyway [[2]]\",\n",
        "        \"Suspect's car spotted 2 miles from scene [[3]]\",\n",
        "        \"Security footage shows figure in red jacket [[4]]\"\n",
        "    ]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "def generate_embedding(text):\n",
        "    # Create embeddings for semantic search [[1]]\n",
        "    \"\"\"response = client.models.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            texts=[text],\n",
        "            task_type=\"retrieval_document\"\n",
        "        )\n",
        "    return response.embeddings[0].values\"\"\"\n",
        "    response = client.models.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            contents=[text],\n",
        "            config=types.EmbedContentConfig(\n",
        "                task_type=\"retrieval_document\",\n",
        "            ),\n",
        "        )\n",
        "    return [e.values for e in response.embeddings]\n",
        "\n",
        "# Generate embeddings for all clues\n",
        "df[\"embedding\"] = df[\"text\"].apply(generate_embedding)\n",
        "\n",
        "# Build FAISS vector index [[2]]\n",
        "embeddings = np.array(df[\"embedding\"].tolist())\n",
        "# Reshape the embeddings to 2 dimensions\n",
        "embeddings = embeddings.reshape(embeddings.shape[0], embeddings.shape[2])  # Reshape to (num_embeddings, embedding_dim)\n",
        "dimension = embeddings.shape[1]\n",
        "faiss_index = faiss.IndexFlatL2(dimension)\n",
        "faiss_index.add(embeddings)\n",
        "\n",
        "def rag_query(query, top_k=2):\n",
        "    # Retrieve relevant clues [[9]]\n",
        "    query_embedding = generate_embedding(query)\n",
        "    # Reshape query_embedding to 2D\n",
        "    query_embedding = np.array(query_embedding).reshape(1, -1)\n",
        "    distances, indices = faiss_index.search(query_embedding, top_k)\n",
        "    relevant_clues = df.iloc[indices[0]][\"text\"].tolist()\n",
        "\n",
        "    # Generate structured response [[9]]\n",
        "    prompt = f\"\"\"\n",
        "    Use these clues to answer in JSON format:\n",
        "    {relevant_clues}\n",
        "\n",
        "    Query: {query}\n",
        "    JSON keys: hypothesis, confidence, related_clues\n",
        "    \"\"\"\n",
        "    response = core_model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "# Example RAG output\n",
        "print(rag_query(\"Who was near the park?\"))\n",
        "# Output: {\"hypothesis\": \"Victim and suspect near park\", \"confidence\": 0.85, \"related_clues\": [1, 4]}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "ZSuwpwZ-gr-k",
        "outputId": "3248d41d-1e89-4606-e2e7-3c20f45fc7de"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"hypothesis\": \"Victim\",\n",
            "  \"confidence\": \"high\",\n",
            "  \"related_clues\": [1]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    }
  ]
}